{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.special as sc\n",
    "import scipy.stats as stats\n",
    "from scipy._lib.doccer import extend_notes_in_docstring\n",
    "from scipy.optimize import root_scalar\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats._censored_data import CensoredData\n",
    "from scipy.stats._continuous_distns import _check_fit_input_parameters\n",
    "from scipy.stats._distn_infrastructure import _ShapeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weibull_gen(rv_continuous):\n",
    "    r\"\"\"\n",
    "    DESCRIPTION NEEDS TO BE UPDATED\n",
    "    Weibull continuous random variable.\n",
    "\n",
    "    The Weibull Minimum Extreme Value distribution, from extreme value theory\n",
    "    (Fisher-Gnedenko theorem), is also often simply called the Weibull\n",
    "    distribution. It arises as the limiting distribution of the rescaled\n",
    "    minimum of iid random variables.\n",
    "\n",
    "    %(before_notes)s\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    weibull_max, numpy.random.Generator.weibull, exponweib\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The probability density function for `weibull_min` is:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        f(x,k,\\lambda) = \\frac{k}{\\lambda} \\left( \\frac{x}{\\lambda} \\right)^{k-1} \\exp(-(\\frac{x}{\\lambda} )^c)\n",
    "\n",
    "    for :math:`x > 0`, :math:`c > 0`.\n",
    "\n",
    "    `weibull_min` takes ``c`` as a shape parameter for :math:`c`.\n",
    "    (named :math:`k` in Wikipedia article and :math:`a` in\n",
    "    ``numpy.random.weibull``).  Special shape values are :math:`c=1` and\n",
    "    :math:`c=2` where Weibull distribution reduces to the `expon` and\n",
    "    `rayleigh` distributions respectively.\n",
    "\n",
    "    Suppose ``X`` is an exponentially distributed random variable with\n",
    "    scale ``s``. Then ``Y = X**k`` is `weibull_min` distributed with shape\n",
    "    ``c = 1/k`` and scale ``s**k``.\n",
    "\n",
    "    %(after_notes)s\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    https://en.wikipedia.org/wiki/Weibull_distribution\n",
    "\n",
    "    https://en.wikipedia.org/wiki/Fisher-Tippett-Gnedenko_theorem\n",
    "\n",
    "    %(example)s\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _shape_info(self):\n",
    "        # tbc: what does integrality & inclusive mean?\n",
    "        return [\n",
    "            _ShapeInfo(\n",
    "                name=\"k\",\n",
    "                integrality=False,\n",
    "                domain=(0, np.inf),\n",
    "                inclusive=(False, False),\n",
    "            ),\n",
    "            _ShapeInfo(\n",
    "                name=\"lambda_\",\n",
    "                integrality=False,\n",
    "                domain=(0, np.inf),\n",
    "                inclusive=(False, False),\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def _pdf(self, x, k, lambda_):\n",
    "        return k / lambda_ * pow(x / lambda_, k - 1) * np.exp(-pow(x / lambda_, k))\n",
    "\n",
    "    def _logpdf(self, x, k, lambda_):\n",
    "        return (\n",
    "            -np.log(lambda_)\n",
    "            + np.log(k)\n",
    "            + sc.xlogy(k - 1, x / lambda_)\n",
    "            - pow(x / lambda_, k)\n",
    "        )\n",
    "\n",
    "    def _cdf(self, x, k, lambda_):\n",
    "        return -sc.expm1(-pow(x / lambda_, k))\n",
    "\n",
    "    def _ppf(self, q, k, lambda_):\n",
    "        # point percentile function\n",
    "        return pow(-sc.log1p(-q), 1.0 / k) * lambda_\n",
    "\n",
    "    def _sf(self, x, k, lambda_):\n",
    "        # Survival Function\n",
    "        # keep the definition to verify logsf, since the numerical integration for logsf\n",
    "        # fails for k>0 and via this definition, _logsf is still part of the testing\n",
    "        return np.exp(self._logsf(x, k, lambda_))\n",
    "\n",
    "    def _logsf(self, x, k, lambda_):\n",
    "        # log survival function\n",
    "        return -pow(x / lambda_, k)\n",
    "\n",
    "    def _isf(self, q, k, lambda_):\n",
    "        # inverse survival function\n",
    "        # return -pow(q *lambda_,1/k)\n",
    "        return pow(-np.log(q), 1 / k) * lambda_\n",
    "\n",
    "    def _munp(self, n, k, lambda_):\n",
    "        # Moments of the distribution\n",
    "        # taken from https://en.wikipedia.org/wiki/Weibull_distribution#Moments -> raw moment\n",
    "        return pow(lambda_, n) * sc.gamma(1.0 + n * 1.0 / k)\n",
    "\n",
    "    def _entropy(self, k, lambda_):\n",
    "        # taken from https://en.wikipedia.org/wiki/Weibull_distribution#Shannon_entropy\n",
    "        gamma = 0.57721566490153286060  # Euler-Mascheroni constant taken from wiki\n",
    "        return gamma * (1 - 1 / k) + np.log(lambda_ / k) + 1\n",
    "\n",
    "    @extend_notes_in_docstring(\n",
    "        rv_continuous,\n",
    "        notes=\"\"\"\\\n",
    "        If ``method='mm'``, parameters fixed by the user are respected, and the\n",
    "        remaining parameters are used to match distribution and sample moments\n",
    "        where possible. For example, if the user fixes the location with\n",
    "        ``floc``, the parameters will only match the distribution skewness and\n",
    "        variance to the sample skewness and variance; no attempt will be made\n",
    "        to match the means or minimize a norm of the errors.\n",
    "        \\n\\n\"\"\",\n",
    "    )\n",
    "    def fit(self, data, *args, **kwds):\n",
    "        if isinstance(data, CensoredData):\n",
    "            if data.num_censored() == 0:\n",
    "                data = data._uncensor()\n",
    "            else:\n",
    "                return super().fit(data, *args, **kwds)\n",
    "\n",
    "        if kwds.pop(\"superfit\", False):\n",
    "            return super().fit(data, *args, **kwds)\n",
    "\n",
    "        # this extracts fixed shape, location, and scale however they\n",
    "        # are specified, and also leaves them in `kwds`\n",
    "        data, fc, floc, fscale = _check_fit_input_parameters(self, data, args, kwds)\n",
    "        method = kwds.get(\"method\", \"mle\").lower()\n",
    "\n",
    "        # See https://en.wikipedia.org/wiki/Weibull_distribution#Moments for\n",
    "        # moment formulas.\n",
    "        def skew(c):\n",
    "            # with k = c\n",
    "            # this is the original implementation from the weibull_min\n",
    "            # it does not depend on lambda. Is this  an issue?\n",
    "            gamma1 = sc.gamma(1 + 1 / c)\n",
    "            gamma2 = sc.gamma(1 + 2 / c)\n",
    "            gamma3 = sc.gamma(1 + 3 / c)\n",
    "            num = 2 * gamma1**3 - 3 * gamma1 * gamma2 + gamma3\n",
    "            den = (gamma2 - gamma1**2) ** (3 / 2)\n",
    "            return num / den\n",
    "\n",
    "        # For c in [1e2, 3e4], population skewness appears to approach\n",
    "        # asymptote near -1.139, but past c > 3e4, skewness begins to vary\n",
    "        # wildly, and MoM won't provide a good guess. Get out early.\n",
    "        s = stats.skew(data)\n",
    "        max_c = 1e4\n",
    "        s_min = skew(max_c)\n",
    "        if s < s_min and method != \"mm\" and fc is None and not args:\n",
    "            return super().fit(data, *args, **kwds)\n",
    "\n",
    "        # If method is method of moments, we don't need the user's guesses.\n",
    "        # Otherwise, extract the guesses from args and kwds.\n",
    "        if method == \"mm\":\n",
    "            c, loc, scale = None, None, None\n",
    "        else:\n",
    "            c = args[0] if len(args) else None\n",
    "            loc = kwds.pop(\"loc\", None)\n",
    "            scale = kwds.pop(\"scale\", None)\n",
    "\n",
    "        if fc is None and c is None:  # not fixed and no guess: use MoM\n",
    "            # Solve for c that matches sample distribution skewness to sample\n",
    "            # skewness.\n",
    "            # we start having numerical issues with `weibull_min` with\n",
    "            # parameters outside this range - and not just in this method.\n",
    "            # We could probably improve the situation by doing everything\n",
    "            # in the log space, but that is for another time.\n",
    "            c = root_scalar(\n",
    "                lambda c: skew(c) - s, bracket=[0.02, max_c], method=\"bisect\"\n",
    "            ).root\n",
    "        elif fc is not None:  # fixed: use it\n",
    "            c = fc\n",
    "\n",
    "        if fscale is None and scale is None:\n",
    "            v = np.var(data)\n",
    "            scale = np.sqrt(v / (sc.gamma(1 + 2 / c) - sc.gamma(1 + 1 / c) ** 2))\n",
    "        elif fscale is not None:\n",
    "            scale = fscale\n",
    "\n",
    "        if floc is None and loc is None:\n",
    "            m = np.mean(data)\n",
    "            loc = m - scale * sc.gamma(1 + 1 / c)\n",
    "        elif floc is not None:\n",
    "            loc = floc\n",
    "\n",
    "        if method == \"mm\":\n",
    "            return c, loc, scale\n",
    "        else:\n",
    "            # At this point, parameter \"guesses\" may equal the fixed parameters\n",
    "            # in kwds. No harm in passing them as guesses, too.\n",
    "            return super().fit(data, c, loc=loc, scale=scale, **kwds)\n",
    "\n",
    "\n",
    "# a is the left end-point (no negative numbers)\n",
    "weibull = weibull_gen(a=0.0, name=\"weibull\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _weibull_tester_gen(rv_continuous):\n",
    "    \"\"\"class to run the tests for weibull\n",
    "    Idea: copy pdf and signature to benchmark others (cdf, sf, ...) via the numerical integration\n",
    "    of rv_continuous\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.elem = weibull_gen(*args, **kwargs)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _shape_info(self):\n",
    "        # tbc: what does integrality & inclusive mean?\n",
    "        return self.elem._shape_info()\n",
    "\n",
    "    def _pdf(self, x, k, lambda_):\n",
    "        return self.elem._pdf(x, k, lambda_)\n",
    "\n",
    "\n",
    "_weibull_tester = _weibull_tester_gen(a=0.0, name=\"weibull_tester\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weibull(k=2, lambda_=2)\n",
    "wt = _weibull_tester(k=2, lambda_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=0.0, wt=0.0\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "la = 2\n",
    "x = 1\n",
    "\n",
    "w = weibull(k=k, lambda_=la)\n",
    "wt = _weibull_tester(k=k, lambda_=la)\n",
    "\n",
    "fun = \"isf\"\n",
    "\n",
    "w_result = eval(f\"w.{fun}({x})\")\n",
    "wt_result = eval(f\"wt.{fun}({x})\")\n",
    "print(f\"w={w_result}, wt={wt_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test this grid. For we want that x or 1/x will represent both odd and even numbers\n",
    "# for k and lambda\n",
    "k_list = [1 / 3, 1 / 2, 1, 2, 2.5, 3]\n",
    "lambda_list = [1 / 3, 1 / 2, 1, 2, 2.5, 3]\n",
    "function_list = [\"cdf\", \"sf\", \"logcdf\", \"isf\", \"sf\"]\n",
    "\n",
    "x_list = [0.1, 1 / 3, 1 / 2, 0.5, 1, 2, 10, 20]\n",
    "import itertools\n",
    "\n",
    "asserter = lambda x, y: np.abs(x - y)\n",
    "fails = []\n",
    "\n",
    "eps_max = 1e-3\n",
    "\n",
    "for fun, k, la, x in itertools.product(function_list, k_list, lambda_list, x_list):\n",
    "    if fun == \"isf\" and x > 1:\n",
    "        continue  # isf is only defined for x<=1\n",
    "\n",
    "    w = weibull(k=k, lambda_=la)\n",
    "    wt = _weibull_tester(k=k, lambda_=la)\n",
    "    w_result = eval(f\"w.{fun}({x})\")\n",
    "    wt_result = eval(f\"wt.{fun}({x})\")\n",
    "    eps = asserter(w_result, wt_result)\n",
    "\n",
    "    assert (\n",
    "        eps < eps_max\n",
    "    ), f\"fun={fun} k={k} la={la} x={x} got w={w_result} & wt={wt_result}\"\n",
    "\n",
    "    if eps > eps_max or np.isnan(w_result):\n",
    "        # print(f\"{fun} x={x} -> eps={eps}\")\n",
    "        print(f\"fun={fun} k={k} la={la} x={x} got w={w_result} & wt={wt_result}\")\n",
    "        fails.append(fun)\n",
    "        # fails.append(f\"k={k} la={la} fun={fun} x={x} got w={w_result} & wt={wt_result}\")\n",
    "\n",
    "# Note:\n",
    "# the numerical integration of the test class fails for logsf for k>1\n",
    "# Therefore it is excluded from the testing. The SF is implemented as exp(logsf(...))\n",
    "# --> so it is still verified\n",
    "assert fails == [], fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Takes long\\ni_moment = [i+1 for i in range(3)]\\n# check moments\\nfor k, la,  i in itertools.product(k_list, lambda_list, i_moment):\\n    w = weibull(k=k, lambda_=la)\\n    wt = _weibull_tester(k=k, lambda_=la)\\n\\n    w_moment = w.moment(i)\\n    wt_moment = wt.moment(i)\\n    if asserter(w_moment, wt_moment) < eps_max > eps_max:\\n        print(f\"Moment for k={k} la={la} i={i} got w={w_moment} & wt={wt_moment}\")\\n\\n    #assert asserter(w_moment, wt_moment) < eps_max, f\"Moment for k={k} la={la} i={i} got w={w_moment} & wt={wt_moment}\"\\n'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Takes long\n",
    "i_moment = [i+1 for i in range(3)]\n",
    "# check moments\n",
    "for k, la,  i in itertools.product(k_list, lambda_list, i_moment):\n",
    "    w = weibull(k=k, lambda_=la)\n",
    "    wt = _weibull_tester(k=k, lambda_=la)\n",
    "\n",
    "    w_moment = w.moment(i)\n",
    "    wt_moment = wt.moment(i)\n",
    "    if asserter(w_moment, wt_moment) < eps_max > eps_max:\n",
    "        print(f\"Moment for k={k} la={la} i={i} got w={w_moment} & wt={wt_moment}\")\n",
    "\n",
    "    #assert asserter(w_moment, wt_moment) < eps_max, f\"Moment for k={k} la={la} i={i} got w={w_moment} & wt={wt_moment}\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fuerf\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\scipy-test-MZ1tEUu9-py3.12\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2853: IntegrationWarning: The algorithm does not converge.  Roundoff error is detected\n",
      "  in the extrapolation table.  It is assumed that the requested tolerance\n",
      "  cannot be achieved, and that the returned result (if full_output = 1) is \n",
      "  the best which can be obtained.\n",
      "  h = integrate.quad(integ, _a, _b)[0]\n",
      "c:\\Users\\fuerf\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\scipy-test-MZ1tEUu9-py3.12\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2853: IntegrationWarning: The maximum number of subdivisions (50) has been achieved.\n",
      "  If increasing the limit yields no improvement it is advised to analyze \n",
      "  the integrand in order to determine the difficulties.  If the position of a \n",
      "  local difficulty can be determined (singularity, discontinuity) one will \n",
      "  probably gain from splitting up the interval and calling the integrator \n",
      "  on the subranges.  Perhaps a special-purpose integrator should be used.\n",
      "  h = integrate.quad(integ, _a, _b)[0]\n",
      "c:\\Users\\fuerf\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\scipy-test-MZ1tEUu9-py3.12\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2853: IntegrationWarning: The integral is probably divergent, or slowly convergent.\n",
      "  h = integrate.quad(integ, _a, _b)[0]\n"
     ]
    }
   ],
   "source": [
    "# check entropy\n",
    "for k, la in itertools.product(k_list, lambda_list):\n",
    "    w = weibull(k=k, lambda_=la)\n",
    "    wt = _weibull_tester(k=k, lambda_=la)\n",
    "\n",
    "    w_entropy = w.entropy()\n",
    "    wt_entropy = wt.entropy()\n",
    "\n",
    "    assert asserter(w_entropy, wt_entropy) < eps_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method entropy in module scipy.stats._distn_infrastructure:\n",
      "\n",
      "entropy() method of scipy.stats._distn_infrastructure.rv_continuous_frozen instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(w.entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class rv_continuous_frozen in module scipy.stats._distn_infrastructure:\n",
      "\n",
      "class rv_continuous_frozen(rv_frozen)\n",
      " |  rv_continuous_frozen(dist, *args, **kwds)\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      rv_continuous_frozen\n",
      " |      rv_frozen\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  logpdf(self, x)\n",
      " |\n",
      " |  pdf(self, x)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from rv_frozen:\n",
      " |\n",
      " |  __init__(self, dist, *args, **kwds)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  cdf(self, x)\n",
      " |\n",
      " |  entropy(self)\n",
      " |\n",
      " |  expect(self, func=None, lb=None, ub=None, conditional=False, **kwds)\n",
      " |\n",
      " |  interval(self, confidence=None)\n",
      " |\n",
      " |  isf(self, q)\n",
      " |\n",
      " |  logcdf(self, x)\n",
      " |\n",
      " |  logsf(self, x)\n",
      " |\n",
      " |  mean(self)\n",
      " |\n",
      " |  median(self)\n",
      " |\n",
      " |  moment(self, order=None)\n",
      " |\n",
      " |  ppf(self, q)\n",
      " |\n",
      " |  rvs(self, size=None, random_state=None)\n",
      " |\n",
      " |  sf(self, x)\n",
      " |\n",
      " |  stats(self, moments='mv')\n",
      " |\n",
      " |  std(self)\n",
      " |\n",
      " |  support(self)\n",
      " |\n",
      " |  var(self)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from rv_frozen:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  random_state\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scipy.stats._distn_infrastructure.rv_continuous_frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.678938534707747)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
