{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.stats import rv_continuous\n",
    "import numpy as np\n",
    "import scipy.special as sc\n",
    "from scipy.stats._distn_infrastructure import _ShapeInfo\n",
    "from scipy.stats._continuous_distns import _check_fit_input_parameters\n",
    "from scipy.stats._censored_data import CensoredData\n",
    "from scipy._lib.doccer import extend_notes_in_docstring\n",
    "from scipy.optimize import root_scalar\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class weibull_gen(rv_continuous):\n",
    "    r\"\"\"\n",
    "    DESCRIPTION NEEDS TO BE UPDATED\n",
    "    Weibull continuous random variable.\n",
    "\n",
    "    The Weibull Minimum Extreme Value distribution, from extreme value theory\n",
    "    (Fisher-Gnedenko theorem), is also often simply called the Weibull\n",
    "    distribution. It arises as the limiting distribution of the rescaled\n",
    "    minimum of iid random variables.\n",
    "\n",
    "    %(before_notes)s\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    weibull_max, numpy.random.Generator.weibull, exponweib\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The probability density function for `weibull_min` is:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        f(x,k,\\lambda) = \\frac{k}{\\lambda} \\left( \\frac{x}{\\lambda} \\right)^{k-1} \\exp(-(\\frac{x}{\\lambda} )^c)\n",
    "\n",
    "    for :math:`x > 0`, :math:`c > 0`.\n",
    "\n",
    "    `weibull_min` takes ``c`` as a shape parameter for :math:`c`.\n",
    "    (named :math:`k` in Wikipedia article and :math:`a` in\n",
    "    ``numpy.random.weibull``).  Special shape values are :math:`c=1` and\n",
    "    :math:`c=2` where Weibull distribution reduces to the `expon` and\n",
    "    `rayleigh` distributions respectively.\n",
    "\n",
    "    Suppose ``X`` is an exponentially distributed random variable with\n",
    "    scale ``s``. Then ``Y = X**k`` is `weibull_min` distributed with shape\n",
    "    ``c = 1/k`` and scale ``s**k``.\n",
    "\n",
    "    %(after_notes)s\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    https://en.wikipedia.org/wiki/Weibull_distribution\n",
    "\n",
    "    https://en.wikipedia.org/wiki/Fisher-Tippett-Gnedenko_theorem\n",
    "\n",
    "    %(example)s\n",
    "\n",
    "    \"\"\"\n",
    "    def _shape_info(self):\n",
    "        # tbc: what does integrality & inclusive mean?\n",
    "        return [_ShapeInfo(name=\"k\", integrality=False, domain=(0, np.inf), inclusive=(False, False)),\n",
    "                _ShapeInfo(name=\"lambda_\", integrality=False, domain=(0, np.inf), inclusive=(False, False)),]\n",
    "\n",
    "    def _pdf(self, x, k, lambda_):\n",
    "        return k  / lambda_ * pow(x / lambda_ , k-1)*np.exp(-pow(x / lambda_ , k))\n",
    "\n",
    "    def _logpdf(self, x, k, lambda_):\n",
    "        return -np.log(lambda_) + np.log(k) + sc.xlogy(k - 1,  x / lambda_ ) - pow(x / lambda_ , k)\n",
    "\n",
    "    def _cdf(self,x, k, lambda_):\n",
    "        return -sc.expm1(-pow(x / lambda_ , k))\n",
    "\n",
    "    def _ppf(self, q, k, lambda_):\n",
    "        # point percentile function\n",
    "        return pow(-sc.log1p(-q), 1.0/k)*lambda_\n",
    "\n",
    "    def _sf(self, x, k, lambda_):\n",
    "        # Survival Function\n",
    "        return np.exp(self._logsf(x,k , lambda_))\n",
    "\n",
    "    def _logsf(self, x, k, lambda_):\n",
    "        # log survival function\n",
    "        return -pow(x / lambda_, k)\n",
    "\n",
    "    def _isf(self, q, k, lambda_):\n",
    "        # inverse survival function\n",
    "        #return -pow(q *lambda_,1/k)\n",
    "        return pow(-np.log(q),1/k)*lambda_\n",
    "\n",
    "    def _munp(self, n, k, lambda_):\n",
    "        # Moments of the distribution \n",
    "        #taken from https://en.wikipedia.org/wiki/Weibull_distribution#Moments -> raw moment\n",
    "        return pow(lambda_, n) * sc.gamma(1.0+n*1.0/k)\n",
    "\n",
    "    def _entropy(self, k, lambda_):\n",
    "        #taken from https://en.wikipedia.org/wiki/Weibull_distribution#Shannon_entropy\n",
    "        gamma = 0.57721566490153286060 # Euler-Mascheroni constant taken from wiki\n",
    "        return gamma * (1- 1/k) + np.log(lambda_/k) + 1\n",
    "\n",
    "    @extend_notes_in_docstring(rv_continuous, notes=\"\"\"\\\n",
    "        If ``method='mm'``, parameters fixed by the user are respected, and the\n",
    "        remaining parameters are used to match distribution and sample moments\n",
    "        where possible. For example, if the user fixes the location with\n",
    "        ``floc``, the parameters will only match the distribution skewness and\n",
    "        variance to the sample skewness and variance; no attempt will be made\n",
    "        to match the means or minimize a norm of the errors.\n",
    "        \\n\\n\"\"\")\n",
    "    def fit(self, data, *args, **kwds):\n",
    "\n",
    "        if isinstance(data, CensoredData):\n",
    "            if data.num_censored() == 0:\n",
    "                data = data._uncensor()\n",
    "            else:\n",
    "                return super().fit(data, *args, **kwds)\n",
    "\n",
    "        if kwds.pop('superfit', False):\n",
    "            return super().fit(data, *args, **kwds)\n",
    "\n",
    "        # this extracts fixed shape, location, and scale however they\n",
    "        # are specified, and also leaves them in `kwds`\n",
    "        data, fc, floc, fscale = _check_fit_input_parameters(self, data,\n",
    "                                                             args, kwds)\n",
    "        method = kwds.get(\"method\", \"mle\").lower()\n",
    "\n",
    "        # See https://en.wikipedia.org/wiki/Weibull_distribution#Moments for\n",
    "        # moment formulas.\n",
    "        def skew(c):\n",
    "            # with k = c\n",
    "            # this is the original implementation from the weibull_min\n",
    "            # it does not depend on lambda. Is this  an issue?\n",
    "            gamma1 = sc.gamma(1+1/c)\n",
    "            gamma2 = sc.gamma(1+2/c)\n",
    "            gamma3 = sc.gamma(1+3/c)\n",
    "            num = 2 * gamma1**3 - 3*gamma1*gamma2 + gamma3\n",
    "            den = (gamma2 - gamma1**2)**(3/2)\n",
    "            return num/den\n",
    "\n",
    "        # For c in [1e2, 3e4], population skewness appears to approach\n",
    "        # asymptote near -1.139, but past c > 3e4, skewness begins to vary\n",
    "        # wildly, and MoM won't provide a good guess. Get out early.\n",
    "        s = stats.skew(data)\n",
    "        max_c = 1e4\n",
    "        s_min = skew(max_c)\n",
    "        if s < s_min and method != \"mm\" and fc is None and not args:\n",
    "            return super().fit(data, *args, **kwds)\n",
    "\n",
    "        # If method is method of moments, we don't need the user's guesses.\n",
    "        # Otherwise, extract the guesses from args and kwds.\n",
    "        if method == \"mm\":\n",
    "            c, loc, scale = None, None, None\n",
    "        else:\n",
    "            c = args[0] if len(args) else None\n",
    "            loc = kwds.pop('loc', None)\n",
    "            scale = kwds.pop('scale', None)\n",
    "\n",
    "        if fc is None and c is None:  # not fixed and no guess: use MoM\n",
    "            # Solve for c that matches sample distribution skewness to sample\n",
    "            # skewness.\n",
    "            # we start having numerical issues with `weibull_min` with\n",
    "            # parameters outside this range - and not just in this method.\n",
    "            # We could probably improve the situation by doing everything\n",
    "            # in the log space, but that is for another time.\n",
    "            c = root_scalar(lambda c: skew(c) - s, bracket=[0.02, max_c],\n",
    "                            method='bisect').root\n",
    "        elif fc is not None:  # fixed: use it\n",
    "            c = fc\n",
    "\n",
    "        if fscale is None and scale is None:\n",
    "            v = np.var(data)\n",
    "            scale = np.sqrt(v / (sc.gamma(1+2/c) - sc.gamma(1+1/c)**2))\n",
    "        elif fscale is not None:\n",
    "            scale = fscale\n",
    "\n",
    "        if floc is None and loc is None:\n",
    "            m = np.mean(data)\n",
    "            loc = m - scale*sc.gamma(1 + 1/c)\n",
    "        elif floc is not None:\n",
    "            loc = floc\n",
    "\n",
    "        if method == 'mm':\n",
    "            return c, loc, scale\n",
    "        else:\n",
    "            # At this point, parameter \"guesses\" may equal the fixed parameters\n",
    "            # in kwds. No harm in passing them as guesses, too.\n",
    "            return super().fit(data, c, loc=loc, scale=scale, **kwds)\n",
    "\n",
    "# a is the left end-point (no negative numbers)\n",
    "weibull = weibull_gen(a=0.0, name='weibull')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _weibull_tester_gen(rv_continuous):\n",
    "    \"\"\"class to run the tests for weibull\n",
    "    Idea: copy pdf and signature to benchmark others (cdf, sf, ...) via the numerical integration\n",
    "    of rv_continuous\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.elem = weibull_gen(*args, **kwargs)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _shape_info(self):\n",
    "        # tbc: what does integrality & inclusive mean?\n",
    "        return self.elem._shape_info()\n",
    "\n",
    "    def _pdf(self, x, k, lambda_):\n",
    "        return self.elem._pdf(x, k, lambda_)\n",
    "    \n",
    "_weibull_tester = _weibull_tester_gen(a=0.0, name='weibull_tester')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weibull(k=2, lambda_=2)\n",
    "wt = _weibull_tester(k=2, lambda_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=0.0, wt=0.0\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "la = 2\n",
    "x = 1\n",
    "\n",
    "w = weibull(k=k, lambda_=la)\n",
    "wt = _weibull_tester(k=k, lambda_=la)\n",
    "\n",
    "fun=\"isf\"\n",
    "\n",
    "w_result = eval(f\"w.{fun}({x})\")\n",
    "wt_result = eval(f\"wt.{fun}({x})\")\n",
    "print(f\"w={w_result}, wt={wt_result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fun=logsf k=1 la=0.5 x=20 got w=-40.0 & wt=-inf\n",
      "fun=logsf k=2 la=0.5 x=10 got w=-400.0 & wt=-36.7368005696771\n",
      "fun=logsf k=2 la=0.5 x=20 got w=-1600.0 & wt=-36.7368005696771\n",
      "fun=logsf k=2 la=1 x=10 got w=-100.0 & wt=-36.7368005696771\n",
      "fun=logsf k=2 la=1 x=20 got w=-400.0 & wt=-36.7368005696771\n",
      "fun=logsf k=2 la=2 x=10 got w=-25.0 & wt=-24.99999582410784\n",
      "fun=logsf k=2 la=2 x=20 got w=-100.0 & wt=-36.7368005696771\n",
      "fun=logsf k=2 la=3 x=20 got w=-44.44444444444445 & wt=-36.7368005696771\n",
      "fun=logsf k=2.5 la=0.5 x=2 got w=-32.0 & wt=-32.00941275096476\n",
      "fun=logsf k=2.5 la=0.5 x=10 got w=-1788.8543819998317 & wt=-36.04365338911715\n",
      "fun=logsf k=2.5 la=1 x=10 got w=-316.22776601683796 & wt=-inf\n",
      "fun=logsf k=2.5 la=1 x=20 got w=-1788.8543819998317 & wt=-36.04365338911715\n",
      "fun=logsf k=2.5 la=2 x=10 got w=-55.90169943749474 & wt=-inf\n",
      "fun=logsf k=2.5 la=2 x=20 got w=-316.22776601683796 & wt=-inf\n",
      "fun=logsf k=3 la=0.5 x=2 got w=-64.0 & wt=-inf\n",
      "fun=logsf k=3 la=0.5 x=10 got w=-8000.0 & wt=-inf\n",
      "fun=logsf k=3 la=0.5 x=20 got w=-64000.0 & wt=-inf\n",
      "fun=logsf k=3 la=1 x=10 got w=-1000.0 & wt=-inf\n",
      "fun=logsf k=3 la=1 x=20 got w=-8000.0 & wt=-inf\n",
      "fun=logsf k=3 la=2 x=10 got w=-125.0 & wt=-inf\n",
      "fun=logsf k=3 la=2 x=20 got w=-1000.0 & wt=-inf\n",
      "fun=logsf k=3 la=3 x=10 got w=-37.037037037037045 & wt=-36.04365338911715\n",
      "fun=logsf k=3 la=3 x=20 got w=-296.29629629629636 & wt=-36.7368005696771\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "['logsf']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;66;03m#fails.append(f\"k={k} la={la} fun={fun} x={x} got w={w_result} & wt={wt_result}\")\u001b[39;00m\n\u001b[0;32m     25\u001b[0m fails \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(fails))\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m fails \u001b[38;5;241m==\u001b[39m [], fails\n",
      "\u001b[1;31mAssertionError\u001b[0m: ['logsf']"
     ]
    }
   ],
   "source": [
    "#test this grid\n",
    "k_list = [1/4, 1/3, 0.5, 1, 2, 2.5, 3]\n",
    "lambda_list = [0.5, 1, 2, 3]\n",
    "function_list = [\"cdf\", \"sf\", \"logsf\", \"logcdf\", \"entropy\", \"munp\", \"isf\", \"sf\"]\n",
    "function_list = [\"cdf\", \"sf\", \"logsf\", \"logcdf\", \"isf\", \"sf\"]\n",
    "\n",
    "x_list = [0.1, 0.5, 1, 2, 10, 20]\n",
    "import itertools\n",
    "\n",
    "asserter = lambda x, y: np.abs(x-y)\n",
    "fails = []\n",
    "\n",
    "for fun, k, la,  x in itertools.product(function_list, k_list, lambda_list, x_list):\n",
    "    w = weibull(k=k, lambda_=la)\n",
    "    wt = _weibull_tester(k=k, lambda_=la)\n",
    "    w_result = eval(f\"w.{fun}({x})\")\n",
    "    wt_result = eval(f\"wt.{fun}({x})\")\n",
    "    eps = asserter(w_result, wt_result)\n",
    "    if eps > 1e-6:\n",
    "        #print(f\"{fun} x={x} -> eps={eps}\")\n",
    "        print(f\"fun={fun} k={k} la={la} x={x} got w={w_result} & wt={wt_result}\")\n",
    "        fails.append(fun)\n",
    "        #fails.append(f\"k={k} la={la} fun={fun} x={x} got w={w_result} & wt={wt_result}\")\n",
    "\n",
    "fails = list(set(fails))\n",
    "assert fails == [], fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8646647167633873)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.cdf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6321205588285577)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt.cdf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
